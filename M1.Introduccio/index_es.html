<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="can" xml:lang="can" >

<head>
    <meta charset="utf-8" />
    <meta name="generator" content="pandoc" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />        <title>1. Introducción. Conceptos iniciales</title>
    <style>
        code{white-space: pre-wrap;}
        span.smallcaps{font-variant: small-caps;}
        div.columns{display: flex; gap: min(4vw, 1.5em);}
        div.column{flex: auto; overflow-x: auto;}
        div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
        /* The extra [class] is a hack that increases specificity enough to
           override a similar rule in reveal.js */
        ul.task-list[class]{list-style: none;}
        ul.task-list li input[type="checkbox"] {
          font-size: inherit;
          width: 0.8em;
          margin: 0 0.8em 0.2em -1.6em;
          vertical-align: middle;
        }
        .display.math{display: block; text-align: center; margin: 0.5rem auto;}
    </style>
        <link rel="stylesheet" href="aqua.css" />  
    <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
    <![endif]-->
      
</head>

<body>
    <div id="content">
                 <header id="title-block-header">
            <h1 class="title">1. Introducción. Conceptos iniciales</h1>
            <!---->
            <!--  -->
                    </header>
                 <nav id="TOC" role="doc-toc">
            <div class="navContainer">
                 <ul>
<li><a href="#introducción" id="toc-introducción"><span
class="toc-section-number">1</span> Introducción</a></li>
<li><a href="#que-es-y-que-no-es-la-inteligencia-artificial"
id="toc-que-es-y-que-no-es-la-inteligencia-artificial"><span
class="toc-section-number">2</span> Que es y que no es la inteligencia
artificial?</a>
<ul>
<li><a href="#modelos-de-lenguaje-a-gran-escala"
id="toc-modelos-de-lenguaje-a-gran-escala"><span
class="toc-section-number">2.1</span> Modelos de lenguaje a gran
escala</a></li>
<li><a href="#modelos-de-difusión" id="toc-modelos-de-difusión"><span
class="toc-section-number">2.2</span> Modelos de difusión</a></li>
<li><a href="#ejemplos-de-uso-para-empezar-a-experimentar"
id="toc-ejemplos-de-uso-para-empezar-a-experimentar"><span
class="toc-section-number">2.3</span> Ejemplos de uso para empezar a
experimentar</a>
<ul>
<li><a href="#teachable-machine-de-google"
id="toc-teachable-machine-de-google"><span
class="toc-section-number">2.3.1</span> Teachable Machine de
Google</a></li>
<li><a href="#autodraw" id="toc-autodraw"><span
class="toc-section-number">2.3.2</span> Autodraw</a></li>
<li><a href="#quickdraw" id="toc-quickdraw"><span
class="toc-section-number">2.3.3</span> Quickdraw</a></li>
</ul></li>
</ul></li>
</ul>
            </div>
        </nav>
                <main>
            <!-- \awesomebox[violet]{2pt}{\faRocket}{violet}{Lorem ipsum…} -->
            <!-- \awesomebox[violet]{2pt}{\faRobot}{violet}{Lorem ipsum…} -->
            <!-- IMATGE ![Pregunta inicial](./img/proxi/5b.png) -->
            <!-- \textbf{greatest} -->
            <p><img src="img/cc.png" height="50" /></p>
            <p>Este documento está sujeto a una licencia creative
            commons que permite su difusión y uso comercial reconociendo
            siempre la autoría de su creador. Este documento se
            encuentra para ser modificado en el siguiente repositorio de
            github: <!-- CANVIAR L'ENLLAÇ --> <a
            href="https://github.com/arvicenteboix/AIcurscefire">https://github.com/arvicenteboix/AIcurscefire</a>
            </p>
            <h1 data-number="1" id="introducción"><span
            class="header-section-number">1</span> Introducción</h1>
            <p>A buen seguro que muchos de vosotros ya habéis sentido
            hablar de la inteligencia artificial y de todo aquello que
            puede hacer, algunos ya habéis empezado a utilizarlo en
            vuestro día a día y hay que distinguir algunos conceptos
            sobre el que es la IA. En este curso trataremos de haceros
            una introducción sobre las diferentes herramientas que
            existen y como sacarle’#s provecho.</p>
            <p>Hay que tener en cuenta que se trata de un curso de
            iniciación y es posible que os sintáis abrumados de toda la
            información que vayáis a ver, obviamente por la duración del
            curso no vayamos a poder profundizar en muchos de las
            utilidades que os presentaremos, esto ha os lo dejaremos a
            vosotros.</p>
            <p>Los módulos serán breves pero intensos, trataremos de
            ayudaros en todas las dudas que se os plantean, pero
            nosotros también hemos decidido hacer uso de las diferentes
            herramientas de IA para hacer el curso, sobre todo con las
            imágenes, en muchos casos os presentaremos el prompt<a
            href="#fn1" class="footnote-ref" id="fnref1"
            role="doc-noteref"><sup>1</sup></a> y la respuesta que nos
            dará, trataremos de limitar la extensión al que realmente
            necesitáis. Las respuestas os decimos que estarán retocadas
            puesto que la respuesta que mujer siempre cualquiera
            plataforma siempre tiene que #retocar para que sea lo más
            idónea posible al que deseas. Os lo presentaremos con el
            siguiente icono.</p>
            <p>Obviamente es una respuesta muy estándar que no se nos
            hubiera ocurrido escribir.</p>
            <h1 data-number="2"
            id="que-es-y-que-no-es-la-inteligencia-artificial"><span
            class="header-section-number">2</span> Que es y que no es la
            inteligencia artificial?</h1>
            <p>Podemos pensar que todo el que basura al ordenador tiene
            que ver con la inteligencia artificial y obviamente no es
            así, los ordenadores utilizan algoritmos con lenguajes de
            programación para poder automatizar tareas o realizar
            programas.</p>
            <p>Aqui tenso un ejemplo de diagrama de flujo sencillo:</p>
            <!-- DIAGRAMA FLUXE -->
            <figure>
            <img src="img/1.svg"
            alt="Diagrama de flujo. Origen: Wikipedia" />
            <figcaption aria-hidden="true">Diagrama de flujo. Origen:
            Wikipedia</figcaption>
            </figure>
            <p>Estas funciones llevan una lógica atrás, en cambio las IA
            utilizan una manera de programar diferente que pelea
            muchísimas más posibilidades para dar una respuesta más
            creativa #basar en entradas más complejas. Aquí tenemos un
            ejemplo de red neuronal</p>
            <figure>
            <img src="img/2.png"
            alt="Red neuronal. Origen: Wikipedia" />
            <figcaption aria-hidden="true">Red neuronal. Origen:
            Wikipedia</figcaption>
            </figure>
            <div class="note">
            <p>La Inteligencia Artificial (IA) es un campo amplio que
            incluye diferentes técnicas y algoritmos para crear sistemas
            que puedan simular la inteligencia humana. Las redes
            neuronales son una de las técnicas de IA que imitan el
            funcionamiento del cerebro humano para resolver
            problemas</p>
            </div>
            <p>Dentro de la misma inteligencia artificial nos podemos
            encontrar diferentes categorías que iremos viendo a lo largo
            de los próximos años.</p>
            <table>
            <colgroup>
            <col style="width: 33%" />
            <col style="width: 33%" />
            <col style="width: 33%" />
            </colgroup>
            <thead>
            <tr class="header">
            <th>Tipo de IA</th>
            <th>Descripción</th>
            <th>Ejemplos</th>
            </tr>
            </thead>
            <tbody>
            <tr class="odd">
            <td><strong>Inteligencia Artificial Estrecha
            (#IAE)</strong></td>
            <td>La #IAE está programada para realizar una sola tarea, ya
            sea verificar el clima, poder jugar al ajedrez o analizar
            datos sin procesar para escribir informes periodísticos. Los
            sistemas #IAE pueden atender una tarea en tiempo real, pero
            extraen información de un conjunto de datos específico. No
            funcionan fuera de la única tarea para la cual están
            diseñados.</td>
            <td>Verificar el clima, jugar al ajedrez, analizar datos sin
            procesar para escribir informes periodísticos¹.</td>
            </tr>
            <tr class="even">
            <td><strong>Inteligencia Artificial General
            (IAG)</strong></td>
            <td>La IAG puede autoaprendre y autoracionar dentro de su
            entorno. Se centra en tareas complejas y variadas, con la
            misma eficiencia que un ser humano².</td>
            <td>Todavía en desarrollo.</td>
            </tr>
            <tr class="odd">
            <td><strong>Inteligencia Artificial Superintelectual
            (IAS)</strong></td>
            <td>La IAS tiene la capacidad de superar la inteligencia
            humana en todas las áreas².</td>
            <td>Teóricamente posible, pero todavía no existe.</td>
            </tr>
            </tbody>
            </table>
            <h2 data-number="2.1"
            id="modelos-de-lenguaje-a-gran-escala"><span
            class="header-section-number">2.1</span> Modelos de lenguaje
            a gran escala</h2>
            <p>Los Modelos de Lenguaje a gran escala (MLL, por sus
            siglas en inglés, Large Language Modelos) son modelos de
            inteligencia artificial que han sido entrenados con enormes
            cantidades de datos textuales para aprender patrones,
            estructuras y representaciones del lenguaje natural. Estos
            modelos son capaces de realizar tareas relacionadas con el
            procesamiento del lenguaje, como entender el significado de
            frases, generar texto coherente y responder preguntas.</p>
            <p>Ejemplos de MLL incluyen GPT-3 (Generative Pre-trained
            Transformer 3) de OpenAI, BERT (Bidirectional Encoder
            Representations from Transformers) de Google, y T5
            (Texto-tono-Texto Transfer Transformer) de Google.</p>
            <p>Algunas aplicaciones destacadas de los MLL son:</p>
            <ol type="1">
            <li><p><strong>Generación de Texto Creativo</strong>: MLL
            como GPT-3 pueden ser utilizados para generar contenido
            textual creativo, desde poesía hasta narrativa.</p></li>
            <li><p><strong>Asistentes Virtuales Avanzados</strong>: MLL
            se integran en asistentes virtuales para mejorar su
            capacidad de comprensión y generación de respuestas en
            lenguaje natural.</p></li>
            <li><p><strong>Traducción Automática Mejorada</strong>:
            Modelos como T5 han demostrado mejoras significativas en
            tareas de traducción automática.</p></li>
            <li><p><strong>Generación de Resúmenes Automáticos</strong>:
            MLL son empleados para resumir automáticamente textos
            largos, facilitando la extracción de información
            clave.</p></li>
            <li><p><strong>Preguntas y Respuestas</strong>: Modelos como
            BERT son utilizados en sistemas de preguntas y respuestas
            para entender y responder consultas en lenguaje
            natural.</p></li>
            <li><p><strong>Análisis de Sentimiento Avanzado</strong>:
            MLL pueden mejorar la capacidad de analizar el sentimiento
            en grandes cantidades de texto, beneficiando aplicaciones en
            redes sociales y comentarios en linea.</p></li>
            <li><p><strong>Autocompletat de Texto Mejorado</strong>:
            Herramientas de autocompletat, como las utilizadas en
            correos electrónicos o buscas en la web, se benefician de la
            capacidad predictiva de los MLL.</p></li>
            <li><p><strong>Creación de Contenido Multimedia</strong>:
            MLL pueden ser combinados con otros modelos de inteligencia
            artificial para crear contenido multimedia, como imágenes,
            videos o audio, a partir de texto.</p></li>
            <li><p><strong>Creación de Contenido para Redes
            Sociales</strong>: Los MLL son utilizados para generar
            contenido relevante y atractivo en plataformas de redes
            sociales.</p></li>
            <li><p><strong>Reconocimiento de Entidades
            Mejorado</strong>: Modelos como GPT-3 pueden ayudar en la
            identificación y clasificación precisa de entidades en
            textos.</p></li>
            <li><p><strong>Personalización de Recomendaciones</strong>:
            Los LLM contribuyen a mejorar la personalización en sistemas
            de recomendación en áreas como streaming y comercio
            electrónico.</p></li>
            </ol>
            <p>Estas aplicaciones resaltan como los MLL están
            transformando la forma en que las máquinas interactúan con
            el lenguaje humano, abriendo nuevas posibilidades en varias
            áreas.</p>
            <h2 data-number="2.2" id="modelos-de-difusión"><span
            class="header-section-number">2.2</span> Modelos de
            difusión</h2>
            <p>Los modelos de difusión, como DALL-E, son modelos
            generativos avanzados que utilizan técnicas de difusión para
            generar imágenes. Estos modelos se basan en la difusión
            probabilística, que es un proceso estocástico para generar
            datos complejos paso a paso. En lugar de generar
            directamente píxeles de una imagen, los modelos de difusión
            generan una imagen al “difundir” gradualmente información a
            través de múltiples pasos, lo cual permite capturar patrones
            complejos y estructuras en los datos.</p>
            <p>Ejemplos de modelos de difusión incluyen:</p>
            <ol type="1">
            <li><p><strong>DALL-E</strong>: Desarrollado por OpenAI,
            DALL-E es conocido para generar imágenes creativas a partir
            de descripciones textuales. Puede crear imágenes realistas y
            únicas a partir de conceptos específicos.</p></li>
            <li><p><strong>MidJourney</strong>: Otro modelo de difusión
            que se centra en la generación de imágenes a través de
            procesos de difusión probabilística. Puede #utilizar para
            crear imágenes realistas y detalladas.</p></li>
            <li><p><strong>Stable Diffusion</strong>: Un enfoque de
            difusión que busca conseguir una difusión más estable y
            eficiente en términos de entrenamiento y generación de
            imágenes.</p></li>
            </ol>
            <p>Estos modelos de difusión tienen aplicaciones en varias
            áreas, incluyente:</p>
            <ol type="1">
            <li><p><strong>Generación de Imágenes Artísticas y
            Creativas</strong>: Los modelos de difusión como DALL-E se
            utilizan para generar imágenes artísticas y creativas
            basadas en descripciones textuales.</p></li>
            <li><p><strong>Reconstrucción y Mejora de Imágenes</strong>:
            Pueden #aplicar para reconstruir o mejorar imágenes
            existentes, generando versiones más detalladas o
            modificadas.</p></li>
            <li><p><strong>Generación de Contenido Visual
            Personalizado</strong>: Se pueden emplear en la creación de
            contenido visual personalizado para aplicaciones de diseño
            gráfico, publicidad y marketing.</p></li>
            <li><p><strong>Simulación y Entrenamiento en Realidad
            Virtual</strong>: Estos modelos pueden generar escenarios
            visuales realistas para aplicaciones de realidad virtual,
            simulación y entrenamiento.</p></li>
            <li><p><strong>Síntesis de Datos para la
            Investigación</strong>: En ámbitos como la investigación
            científica y médica, los modelos de difusión pueden
            sintetizar datos visuales para hasta
            experimentales.</p></li>
            <li><p><strong>Generación de Contenido para
            Videojuegos</strong>: Pueden #utilizar en la creación de
            mundos y elementos visuales en videojuegos, ofreciendo
            variedad y realismo.</p></li>
            <li><p><strong>Creación de ilustraciones y Arte
            Digital</strong>: Los artistas digitales pueden emplear
            modelos de difusión para crear ilustraciones y arte digital
            único.</p></li>
            </ol>
            <p>Estas aplicaciones destacan la versatilidad de los
            modelos de difusión en la generación de contenido visual,
            desde la creación de arte hasta la simulación de entornos
            complejos. Su capacidad para manejar datos de manera
            probabilística y generar resultados detallados los hace
            valiosos en varias disciplinas creativas y tecnológicas.</p>
            <h2 data-number="2.3"
            id="ejemplos-de-uso-para-empezar-a-experimentar"><span
            class="header-section-number">2.3</span> Ejemplos de uso
            para empezar a experimentar</h2>
            <h3 data-number="2.3.1"
            id="teachable-machine-de-google"><span
            class="header-section-number">2.3.1</span> Teachable Machine
            de Google</h3>
            <p>Teachable Machine de Google es una plataforma que permite
            a los usuarios crear modelos de aprendizaje automático sin
            necesidad de escribir código. Los usuarios pueden entrenar
            modelos de clasificación de imágenes, sonidos o posiciones
            utilizando una interfaz amigable, facilitando la
            incorporación de inteligencia artificial en proyectos
            creativos.</p>
            <p><a
            href="https://teachablemachine.withgoogle.com/">https://teachablemachine.withgoogle.com/</a></p>
            <p>Esta herramienta nos permite entrenar a pequeña escala
            nuestro modelo de inteligencia artificial para un propósito,
            por ejemplo el de reconocer objetos, sonidos o posturas.
            Solo nos hace falta una webcam para hacerlo. Podemos acceder
            a la plataforma desde aquí: <a
            href="https://teachablemachine.withgoogle.com/">https://teachablemachine.withgoogle.com/</a></p>
            <figure>
            <img src="img/24.png" style="width:10cm"
            alt="Teachablemachine" />
            <figcaption aria-hidden="true">Teachablemachine</figcaption>
            </figure>
            <p>Y creamos nuestro primero proyecte</p>
            <figure>
            <img src="img/25.png" style="width:10cm"
            alt="Modelo de imagen" />
            <figcaption aria-hidden="true">Modelo de imagen</figcaption>
            </figure>
            <p>Nosotros hemos preparado un modelo para distinguir entre
            un bolígrafo y unas tijeras, hemos yendo subiendo imágenes
            de cada uno.</p>
            <figure>
            <img src="img/26.png" style="width:10cm"
            alt="Modelo de imagen creado" />
            <figcaption aria-hidden="true">Modelo de imagen
            creado</figcaption>
            </figure>
            <p>Este modelo lo podemos exportar y lo podemos compartir.
            Obviamente el modelo que he creado no es demasiado
            interesante, pero potd dedicarte a entrenar mejores modelos
            con muchas fotografías, de objetos de la clase y crear tu
            propio reconocedor de de objetos. Podéis descargar el modelo
            de de aquí: <a
            href="https://teachablemachine.withgoogle.com/models/9oqm8e4an/">https://teachablemachine.withgoogle.com/models/9oqm8e4an/</a></p>
            <h3 data-number="2.3.2" id="autodraw"><span
            class="header-section-number">2.3.2</span> Autodraw</h3>
            <p>La función principal de AutoDraw es facilitar la creación
            de dibujos reconocibles incluso para aquellos que no son
            hábiles en el dibujo. La herramienta ofrece una variedad de
            iconos y formas que coinciden con el contenido aproximado
            del dibujo original, permitiendo a los usuarios mejorar y
            refinar sus creaciones de manera intuitiva.</p>
            <p><a
            href="https://www.autodraw.com/">https://www.autodraw.com/</a></p>
            <p>Por ejemplo, si dibujamos un barco de la mejor manera que
            sabemos</p>
            <figure>
            <img src="img/3.png" style="width:10cm"
            alt="Imagen dibujada por nosotros" />
            <figcaption aria-hidden="true">Imagen dibujada por
            nosotros</figcaption>
            </figure>
            <p>Al menú arriba la plataforma tratará de averiguar qué
            hemos dibujado y nos proporcionará una imagen un tanto mejor
            dibujada que el que hemos hecho.</p>
            <figure>
            <img src="img/4.png" style="width:10cm"
            alt="Imagen del menú escogida" />
            <figcaption aria-hidden="true">Imagen del menú
            escogida</figcaption>
            </figure>
            <h3 data-number="2.3.3" id="quickdraw"><span
            class="header-section-number">2.3.3</span> Quickdraw</h3>
            <p>Quick, Draw! es un juego en linea desarrollado por Google
            que utiliza inteligencia artificial para reconocer y
            clasificar dibujos realizados por los usuarios en un tiempo
            limitado. El funcionamiento básico del juego es el
            siguiente:</p>
            <ol type="1">
            <li><p><strong>Dibujo Rápido</strong>: El jugador recibe una
            palabra sugerida y tiene un tiempo limitado (generalmente 20
            según) para dibujar el objeto o concepto asociado en un
            lienzo digital.</p></li>
            <li><p><strong>Reconocimiento en Tiempo Real</strong>:
            Mientras el jugador dibuja, la inteligencia artificial
            intenta adivinar el que está representando en tiempo real.
            Utiliza algoritmos de aprendizaje automático y redes
            neuronales para analizar el trazo del dibujo.</p></li>
            <li><p><strong>Retroalimentación Instantánea</strong>: Una
            vez que se completa el tiempo de dibujo, el juego
            proporciona retroalimentación instantánea sobre si la
            inteligencia artificial ha reconocido correctamente el
            dibujo o no. Además, muestra ejemplos de cómo otros usuarios
            han representado la misma palabra.</p></li>
            <li><p><strong>Contribución a Conjunto de Datos de
            Entrenamiento</strong>: Los dibujos realizados por los
            usuarios no solo son parte del juego, sino que también
            contribuyen al conjunto de datos utilizado para entrenar y
            mejorar los algoritmos de reconocimiento de Google.</p></li>
            </ol>
            <p>En resumen, Quick, Draw! combina la diversión de un juego
            en linea con la recopilación de datos para mejorar los
            modelos de inteligencia artificial de reconocimiento de
            patrones. Los usuarios contribuyen a la mejora de la
            tecnología mientras participan en una experiencia
            interactiva y creativa.</p>
            <p><a
            href="https://quickdraw.withgoogle.com/">https://quickdraw.withgoogle.com/</a></p>
            <p>Se trata de un juego sencillo que nos permitirá
            experimentar con una red neuronal. Esta tratará de averiguar
            qué es el que estamos dibujando con un tiempo de 20
            segundos.</p>
            <figure>
            <img src="img/5.png" style="width:10cm" alt="Juego" />
            <figcaption aria-hidden="true">Juego</figcaption>
            </figure>
            <figure>
            <img src="img/6.png" style="width:10cm"
            alt="Imagen a averiguar" />
            <figcaption aria-hidden="true">Imagen a
            averiguar</figcaption>
            </figure>
            <figure>
            <img src="img/7.png" style="width:10cm"
            alt="Nuestro dibujo" />
            <figcaption aria-hidden="true">Nuestro dibujo</figcaption>
            </figure>
            <p>Así irá tirando durante 6 imágenes. Es un buen ejercicio
            para entender como funcionan las redes neuronales.</p>
            <figure>
            <img src="img/8.png" style="width:10cm"
            alt="Nos ha acertado los 6" />
            <figcaption aria-hidden="true">Nos ha acertado los
            6</figcaption>
            </figure>
            <section id="footnotes"
            class="footnotes footnotes-end-of-document"
            role="doc-endnotes">
            <hr />
            <ol>
            <li id="fn1"><p>Prompt, es el texto que escribes a la
            plataforma para que interpreto el que realmente necesitas.
            Entraremos con más detalle a la próxima unidad.<a
            href="#fnref1" class="footnote-back"
            role="doc-backlink">↩︎</a></p></li>
            </ol>
            </section>
        </main>
        

        <!--- Modal images -->

        <!-- The Modal -->
        <div id="myModal" class="modal">

            <!-- The Close Button -->
            <!--span class="close">&times;</span-->

            <!-- Modal Content (The Image) -->
            <img class="modal-content" id="img01">

            <!-- Modal Caption (Image Text) -->
            <div id="caption"></div>
        </div>

        <!-- End Modal Images -->

        <script>
            function ModalizeImages() {
                // Script basat en https://www.w3schools.com/howto/howto_css_modal_images.asp
                // PEr ampliar imatges en fer click

                // Get the modal
                var modal = document.getElementById("myModal");

                var modalImg = document.getElementById("img01");
                var captionText = document.getElementById("caption");

                // Get the image and insert it inside the modal - use its "alt" text as a caption
                //var img = document.getElementById("myImg");
                document.querySelectorAll("img").forEach((img => {
                        img.onclick = function() {
                            modal.style.display = "block";
                            modalImg.src = this.src;
                            captionText.innerHTML = this.alt;
                        }
                    }))
                    // Get the <span> element that closes the modal
                var span = document.getElementsByClassName("close")[0];

                // When the user clicks on <span> (x), close the modal
                //span.onclick = function() {
                myModal.onclick = function() {
                    modal.style.display = "none";
                }


            }


            function markItem(id) {
                // Restaurem format de tots
                document.querySelectorAll("#TOC a").forEach(function(item) {
                        //item.style.fontWeight = "300";
                        item.classList.remove("navItemSelected");
                    })
                    //item.style.color = "#ff0000";

                // Afegim format
                let items = document.querySelectorAll("#TOC a[href='#" + id + "']");
                items.forEach(function(item) {
                    //item.style.fontWeight = "bolder";
                    item.classList.add("navItemSelected");
                })

            }

            var observer = new IntersectionObserver(function(entries) {
                // isIntersecting is true when element and viewport are overlapping
                // isIntersecting is false when element and viewport don't overlap
                if (entries[0].isIntersecting === true) {
                    let id = entries[0].target.id;
                    markItem(id);
                }

            }, {
                threshold: [0]
            });

            window.addEventListener("load", function() {
                document.querySelectorAll("h1, h2, h3").forEach(function(item) {
                    observer.observe(item);
                });

                document.querySelectorAll("#TOC a").forEach(function(item) {
                    item.addEventListener("click", function(item) {
                        markItem(item.id);
                    })
                })

                // Fem modals totes les imatges
                ModalizeImages();
            })

            document.querySelector("#TOC").addEventListener("click", function(event) {
                let toc = event.target
                if (toc.offsetWidth > 10) {
                    toc.classList.add("minimizedToc");
                }
            })

            document.querySelector("#TOC").addEventListener("mouseover", function(event) {
                let toc = event.target
                if (toc.classList.contains("minimizedToc"))
                    toc.classList.remove("minimizedToc");
            })


            //item.style.color = "#ff0000";
        </script>
    </div>
</body>

</html>